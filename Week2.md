# DAY - 7

## Job roles

The AI job market has been growing at a phenomenal rate for some time. Here are some job roles to consider if you want to work with artificial intelligence technology. In each description, you’ll find information about what people do and the skills they use to do it.

- **Machine learning engineer:** <br>
Machine learning engineers are at the **intersection of software engineering and data science**. They use big data tools and programming frameworks to create production-ready and scalable data science models that can handle terabytes of real-time data.

Machine learning engineer jobs are best for anyone with a background that combines data science, applied research, and software engineering. You can thrive if you have strong mathematical skills, experience in machine learning, deep learning, neural networks, and cloud applications, and programming skills in Java, Python, and Scala. It also helps to be well-versed in an integrated development environment (IDE), like IBM Watson Studio.

- **Data scientist:** <br>
Data scientists use machine learning and predictive analytics to gain insights from large amounts of data. To prepare, you should build your expertise in **big data platforms and tools**, perhaps including Hadoop, Pig, Hive, Spark, and MapReduce. It would be helpful if you are fluent in at least two programming languages, including structured query language (SQL), Python, Scala, and Perl. You should also invest some time learning descriptive and inferential statistics.

This is a field in which most people have earned a master's or doctoral degree. You would also benefit from non-technical workplace skills, like communication, collaboration, intellectual curiosity, and business acumen.

- **Business intelligence developer:** <br>
Business intelligence (BI) developers design, model, build, and maintain data sets for complex data platforms. Their primary job is to analyze complex data and look for current business and market trends to help increase the profitability and efficiency of their organization. Strong technical and analytical skills would help you break into this field, as well as collaboration and problem-solving skills.

For this career, you should consider earning a bachelor’s degree in computer science, engineering, or a related field, or a combination of certifications and on-the-job experience. Companies usually prefer candidates with **experience in data warehouse design or with data mining**, and knowledge of BI technologies, **SQL queries, SQL Server Reporting Services (SSRS), and SQL Server Integration Services (SSIS)**.

- **Robotic scientist:** <br>
Robots can automate jobs, but they require programmers working behind the scenes to ensure they function well. Robotics engineers build and maintain AI-powered robots. Their job is to design and build mechanical devices that can perform tasks with commands from humans. To succeed in robotics, you should learn to code in various programming languages and to develop working prototypes.

To prepare for a career in robotics, you might earn a bachelor’s degree in one of the following disciplines: robotic engineering, mechanical engineering, electro-mechanical engineering, or electrical engineering. Companies also look for professionals with specializations in advanced mathematics, physical sciences, life sciences, computer science, computer-aided design and drafting (CADD), physics, fluid dynamics and materials science, and a related AI certification.

- **Software engineer:** <br>
AI software engineers **build software products for AI applications**. AI software engineers develop and maintain the software that data scientists and architects use. They stay informed and updated about new artificial intelligence technologies.

As an AI software engineer, you’d be skilled in software engineering and artificial intelligence. You’d have programming skills, statistical skills, and analytical skills. Companies typically look for a bachelor’s degree in computer science, engineering, physics, mathematics, or statistics.

- **Natural language processing engineer:** <br>
Natural language processing (NLP) engineers are AI professionals who specialize in human language, including spoken and written information. The engineers who work on voice assistants, speech recognition, document processing, and so on use NLP technology.

For the role of an NLP engineer, organizations expect you to have a specialized degree in computational linguistics or a combination of computer science, mathematics, and statistics.

## Skills to build

- **Baseline Skills:**
     - Linear algebra
     - Probability
     - Statistics
     - Signal processing
     - Big data
- **Workplace Skills:**
     - Communication skills
     - Teamwork and collaboration
     - Problem solving
     - Decision making
     - Analytical thinking
     - Time management
     - Business intelligence
     - Critical thinking

- **Advanced technical skills:**
     - Programming languages (Python, R, Java, C++)
     - Frameworks and libraries (TensorFlow, SciPy, Numpy)
     - Neural networks
     - Machine learning
     - Deep learning
     - Shell scripting
     - Cluster analysis
     - Tableau
     - Microsoft Power BI

## Machine learning models

Machine learning is, in the end, about making predictions using **statistics and calculus**; both of which are used in bits of code called **machine learning algorithms**. These bits of code, in turn, can be organized in large-scale computer programs called **machine learning models**. Your understanding of machine learning and how it’s executed in **IBM Watson Studio** starts with an exploration of these two concepts.

- **Machine Learning Algorithms:** A machine learning algorithm is a set of program code. If you’ve ever worked with code, you might know what a function is. A function is a set of logical operations that inputs some sort of data, analyzes or transforms it, and then outputs a result. But in a machine learning algorithm, that **analysis often has a specific goal: to recognize patterns in data sets**. For example, an algorithm in an AI weather prediction system might ingest a series of sunlight measurements and water temperatures, then analyze and output a pattern describing how these factors appear to influence each other.
- **Machine Learning Models:** A machine learning model is a group of machine learning algorithms. Operating together, they detect patterns among their algorithms’ output and use those patterns **to make predictions**. For example, a model whose algorithms look at patterns regarding temperature, climate, geography, and so on might predict a rainy-day next Saturday.

How is this different from the way conventional computer programs operate? A machine learning model doesn’t depend only on a human to write its code or to adjust its programming if its predictions aren’t right. Instead, **a machine learning model can reprogram itself**. So if, for example, a weather model tends to get a certain type of prediction wrong, it can adjust its algorithms (weights and biases, statistical constructs) to improve the accuracy of its predictions.

Why are you learning about this? Because creating machine learning models is the primary job of IBM Watson Studio. Its integrated development environment (IDE) makes this difficult task easier, faster, and more affordable. This is the future of computer programming.

## Watson Studio was born from a need

Until about 2015, artificial intelligence scientists found that building AI systems was **cumbersome and time-consuming**. They might need to search the web, review components, hand-code connections to big data tools and learn to use them, and more. This was an **expensive problem** for laboratories and companies trying to develop and market useful systems.

Even worse, working with AI **broke up workflows**. Developers toggled from one technology to another, jumping back and forth between workspaces, and repeatedly switching programming tools to get tasks done.

These problems slowed down the adoption of AI systems, making it **hard to integrate them into existing technology** such as medical care or automobiles. Once all the elements were working together and launched, it was difficult to provide support when help was needed.


## IBM Watson Studio fulfills the need

IBM’s Watson Studio solution is what researchers call an integrated development environment (IDE). Named after IBM’s founder, it pulls together the most useful development and analytic tools, wrapping them in a development platform that is powerful enough to meet large-scale challenges, yet simple enough that developers can master it quickly.

IBM Watson Studio solves AI development problems. With IBM Watson Studio, businesses can simplify data projects with a streamlined process to extract insights from data to help them get smarter faster. It delivers an easy-to-use, collaborative data science and machine learning environment to build and train models, prepare and analyze data, and share insights all in one place.

IBM Watson Studio is a single environment for sharing work to solve problems within the system, rather than starting from scratch every time a new issue arises. And developers can use that efficiency to quickly dive into building machine learning and deep learning algorithms. 

Watson Studio gives developers:

- A collaborative data science and machine learning environment
- Easy visualizations with drag-and-drop code
- An efficient workflow
- A built-in neural network modeler
- Open-source tools such as Jupyter Notebooks and RStudio

Watson Studio’s features sound impressive. But do they really make a difference? Read on to learn how they help developers working on real-world projects.

## IBM Watson Studio speeds data input and insights output

Watson Studio is more than a collection of resources that can communicate with each other. It eases ingesting data into an AI system, organizes assets, performs complex analysis, and displays results that make complicated issues simpler to understand.


- **Automated data preparation:** 
IBM Watson Studio has a feature called AutoAI that prepares raw data for machine learning. It can apply various algorithms to clean and structure the data, automatically select an appropriate model, and optimize its output for the fastest, most useful output.

- **Visual neural network design:** 
Watson Studio helps developers create machine learning flows and design neural networks visually, using a simple drag-and-drop interface and open source code libraries.

- **Sophisticated analysis and prediction:** 
Watson Studio recommends algorithms and uses the latest neural networks to predict and build patterns. It helps programmers create visualizations simply by selecting data items, after which the system itself can choose the best way to visualize its findings.


- **Unified dashboard displays:** 
Watson Studio dashboards not only visualize the results of complex analyses, they also gather related views on data into a single place where clients can find and understand the information they seek. These dashboards don’t require specialized coding or database skills, and researchers can easily share them across the internet.

IBM Watson Studio is designed to make data science a team sport that helps developers learn, create, and collaborate on great machine learning models. 

## When a classical computer program is not enough

Today businesses, industries, and governments need more computing power than seemed enough just a few years ago. They depend on data analysis that can only be developed from machine learning models, using tools like IBM Watson Studio.

Consider, for example, the problem faced by a sneaker manufacturer that wants to know what customers think and say about its products. This information could help it plan product distribution for today and keep up with new trends in the future. The best way to discover these things might be to study product reviews people have posted, and also study IM texts sent by the manufacturer’s teen and young adult customers. What are they saying? What do they love or hate? What new thing did they just see that they really want to buy?

Here are some of the things that make this discovery difficult.

- Millions of social media posts hit the internet every hour across Twitter, TikTok, and others.
- Those posts cover zillions of topics, most of which have nothing to do with sneakers.
- Posts that do mention sneakers might do so in countless different contexts.

Even if a conventional computer could be programmed and given enormous resources to keep up with this flood of data, sneaker fashions change without warning—and those changes cannot be predicted or prepared for with traditional program code.

But with IBM Watson Studio, a modest-size team of specialists could build a machine learning model that will, as time goes by, get better and better at spotting major trends in sneaker design. It could even follow celebrity fashions, then begin predicting new trends more and more effectively.

# DAY - 8

## Your AI machine learning project

Imagine that you’re an up-and-coming coder looking for your big break. Yesterday, you got a phone call from a major bank in Germany. A few hours later you found yourself flying across the ocean on a transcontinental jet! This could be your chance to make your name in AI machine learning. You leaned your seat forward and studied the materials that the bank sent you.

## A terrific opportunity

The bank wants to protect itself from the risk of making loans that are never repaid.

- It’s preparing to launch a new website on which customers can submit requests for loans up to €10,000 and, if their credit is sound, get instant approval.
- The good news is that this will **attract customers** who want to apply for loans quickly, **without a lot of fuss**.
- The bad news is that it will give the **bank almost no time to investigate **each applicant’s credit risk, then reject those who might default on their loan, ultimately costing the bank millions of euros.

The bank wants you to lead the development of an AI machine learning system that can **rapidly predict the risk of granting a loan** for each customer who applies.

## The scope of your experiment

Using simulations of IBM Watson Studio, you’ll build an AI machine learning model, train algorithms on the same data set of bank loans and defaults, then test them competitively, using additional data, to see which predicts defaults most accurately.

## Your data set

You’ll use data from a real German bank that’s fictionalized for this simulation.
The file contains records of five thousand past loans.
Each record includes ample data such as the customer’s credit rating, bank account balances, loan purpose, and more—and whether the borrower paid or defaulted on the loan.

## Your to-do list
Using IBM Watson Studio and a data set, you will simulate the following steps.

- Set up a new project in IBM Watson Studio.
- Create a learning model designed to predict whether an applicant is more likely to pay back or default on a loan.
- Train your model on 90% of your data set, including loan outcomes.
- Test the model on a test set of data (the remaining 10% of the data in the data set) to see which algorithm gives the best predictions.
- Save the final model with highest confidence as a Jupyter notebook.


### Start a project and upload data 
1. After you log into IBM Cloud, you’ll find the Dashboard. This Dashboard lets you access the 
tools, services, resources and more in your IBM Cloud account. Select Catalog on the top 
toolbar. 
The IBM Cloud dashboard 
With several bank IT workers looking on, you log into IBM Cloud. As it comes up, you 
explain that you can access Watson Studio in just a few steps through an IBM Cloud 
account. This acts as your doorway to amazing AI resources. 
2. This is the catalog of IBM products and services. It is a best practice to create database storage 
first. Type “object storage” in the Search field and select Enter 
3. Select Object Storage. 
4. For this simulation, you are using a free account, so you don’t need to review a pricing plan. 
Select the Next arrow to continue. 
5. Scroll down to the Configure your resource section. Developers would say that you’re going to 
“provision” the object storage. A Service name is automatically generated, but you should name 
it something meaningful to your project. Type “Cloud Object Storage-Risk_Fraud” in the Service 
name field and select Enter. 
6. You don’t need to fill out the other fields. In the lower right select Create.  
7. Now that you’ve provisioned the Cloud Object storage, select the sandwich icon at the top left 
to display the navigation menu. 
8. Select Resource list from the navigation menu. 
9. This displays a list of the resources that you have created. Select Storage to see that the Cloud 
Object Storage_Risk_Fraud that you just created is listed. 
10. Select Catalog on the top toolbar. 
11. Notice on the left side under Category that there is a large collection of available tools. Select 
the AI / Machine Learning category. 
An AI / machine learning service 
Now you’re through the IBM doorway. You’ve finished basic bookkeeping and you’re 
ready set up a project in IBM Watson Studio. Some of the IT folks haven’t seen anything 
like this before, so more of them crowd around to watch you get ready. 
12. Notice there are several AI and machine learning products listed. Find and select the Watson 
Studio block.  
13. For this simulation, you are using a free account, so you don’t need to review a pricing plan. Note 
that the location selected is Dallas (us-south). Scroll down to reveal the Configure your 
resource section, then select the Next arrow to continue. 
14. Under the Configure your resource section, the Service name is automatically generated, in 
this case Watson Studio-dl. Type “Watson Studio-AI Fundamentals” in the Service name field 
and select Enter. 
15. You don’t need to fill out the other fields. In the lower right, assume that you’ve checked that 
you have read and agree to the license agreements, then select Create. 
16. You’ve provisioned the IBM Watson Studio service! Notice the service name you picked displays 
in the upper left. Now, you need to create a new project. Select Launch in IBM Cloud Pak for 
Data.  
17. On the Build and manage ML models pop-up, Provision Watson Machine Learning is select by 
default. Select Next. 
A new AI project 
With your service set up, you’ll create the AI project itself. This involves launching it, 
naming it, and associating it with the database that you’ll use to test your machine 
learning models. 
18. Make sure that Dallas displays in the Select a region field. Since Dallas was selected for 
Watson Studio, you must make sure that you select Dallas for all the other services. Select the 
Next arrow to continue. 
19. Under the Configure your resource section, name your service. Type “Machine Learning
Risk_Fraud” in the Service name field. Then select Create. 
20. You are working on a new project, so select New project to create an empty project and then 
select Next. 
21. Under the Define details section, you can name your project. Type “Risk_Fraud” in the Name 
field. Select the Next arrow to continue. 
22. Notice under Storage that IBM Watson Studio already provisioned the Cloud Object Storage 
(COS) that you created earlier so you have a database. This COS can store unstructured data like 
images and text. Soon, you’ll work with structured data in a comma-separated values (CSV) file. 
Select Create.  
23. You’ve created the project! This is the IBM Watson Studio Projects dashboard. You can see your 
project name at the top. This is the Overview tab. Select the Assets tab.  
24. It’s time to upload your data set. Select Drop data files here to open your local drive and find 
the german_credit_data_biased_training.csv file that you’ll be working with for the project. 
25. Drag and drop the german_credit_data_biased_training.csv file to Drop data files or browse 
for files to upload under Data in this project. 
26. Notice your CSV file is right there for you. Select “german_credit_data_biased_training.csv”. 
27. A Preview assets page opens so you can now preview your data. Take a moment to check out 
the data that displays. Select the Next arrow to continue.


### Create and run AI models 
1. Now that you’ve set up your data set in cloud storage, it is time to build the AI models. Select New 
asset to start creating your AI model. 
AI models 
Creating artificial intelligence models used to be an incredibly complex and difficult task. 
But today you can show off to your colleagues how IBM Watson Studio does this for you—
 automatically! 
2. On the left side, there is a Tool type list. Select the Automated builders tool. AutoAI is the only 
Automated builder displayed. With AutoAI, you will be able to quickly set up and run AI models 
using your data to train and test the models. Select AutoAI. 
3. Creating and testing AI models is called experimenting. Now it’s time to create your AutoAI 
experiment. Type “Loan Risk” in the Name field to name your model and press Enter. 
4. In the Define configuration section, you’ll see a machine learning service isn’t associated with your 
project yet. Let’s take care of that now. Select the Associate a Machine Learning service instance 
link. 
5. On the Associate service page, you’ll see all the services you’ve created that can be associated with 
your experiment. Right now, there’s only one service displayed: Machine Learning-Risk_Fraud. 
Select the checkbox next to the service and then select Associate. 
6. Now that you’ve associated your machine learning service, select Reload to refresh the page. 
7. You can see Machine Learning-Risk_Fraud displayed in the Watson Machine Learning Service 
Instance field now. You’re ready to create your AutoAI experiment. Select Create. 
8. It’s time to add your data source. Select Select from project to find the data source you added 
previously.  
Your experiment 
You promised the bank you’d run several different machine learning algorithms competitively. 
You’d train them all on the same partial set of historic data about people who took out loans 
and then paid them back or defaulted on them. Then you’d test how well they performed, based 
on what they’d learned, by feeding them identical sets of new data, without telling them who 
defaulted. Each algorithm would make predictions about everyone in the new data set, 
classifying people as Risk or No Risk. 
9. On the left, you’ll see Categories listed. Select Data asset to reveal your data assets.  
10. You can see your data asset. Select the check box next to: german_credit_data_training.csv.  
11. On the right, information about the asset is displayed including: name, asset type, size, and when it 
was modified and created. Select Select asset. 
12. Now it’s time to configure the details for your experiment. The first question that displays asks if you 
want to create a time series forecast. For this experiment, you don’t want to do that, so select No. 
13. The next question that displays asks what you want to predict. This is asking what column from your 
data set you want the AI model to predict. Select Select prediction columns to open the drop-down 
list. 
14. Next to Risk are the letters “STR”. This indicates that the data type in the Risk column is a String. 
Strings are a sequence of letters, digits, punctuation, and so on. In this case, it’s text data. Since 
you’re trying to predict which individuals are good risks for loans, select Risk.  
15. The PREDICTION TYPE that Watson AutoAI selected is Binary Classification. You’re trying to 
determine whether an individual presents a Risk or No Risk, which is a classification with only two 
options, so leave the prediction type as Binary Classification. Select the Next arrow to continue. 
16. By default, Accuracy & run time is selected in the OPTIMIZED FOR field. This means when Watson 
is evaluating which algorithm is best it will optimize by balancing accuracy and speed. Select 
Experiment settings to make further changes.  
17. This is the General tab. It shows what you selected on the previous page. Binary classification is 
the prediction type, No Risk is the positive class, and Accuracy is the optimize metric. Select the 
Next arrow to continue. 
Competitive algorithms 
Some folks watching you had expected you to create mathematical algorithms that could 
analyze data and predict credit risk. It’s time to astonish them. How? By using Watson 
Studios to line them up quickly. 
18. Scroll down to view the Algorithms to include section, notice Gradient Boosting Classifier is not 
selected. Select the check box next to Gradient Boosting Classifier. 
19. Scroll down to view the Algorithms to use section. Watson AutoAI lets you test up to four 
algorithms. Select the Next arrow to continue. 
20. By default, Watson will select the best two algorithms to test on the data. Select Data source from 
the left menu. 
21. Scroll down to view the Training and holdout method section.  
The Training data split slider lets you choose how much of the data set to use for training 
and how much to use for testing. By default, 90% of the data set is used for training and 
10% of the data set is used to test how the AI model is performing. Hover over the 
underlined words to see more about each field in this section. 
22. Below the Training data split is the Select features to include section. Here, you can select which 
columns (or features) in the data set to use for training and testing. There are three pages of data. 
Select the forward arrow to page through the columns in the data set. 
23. All the features in the data set are available except Risk because that’s what is being tested. By 
default, all the features are selected. Select the check box next to Telephone to deselect it and not 
use this feature in the experiment. 
24. Select Save settings to confirm all your choices. 
25. Everything is set up! Select Run experiment to start the experiment. 
Launch time! 
You’re about to launch the experiment. Your models will ingest the historic training data, 
then run the new data and make their predictions. Like people watching a horse race, 
everyone leans in to see what happens. 
26. The Relationship map shows by default. Select the Swap view link under Progress map to display 
the Progress map.  
27. Here, the Progress map shows the two models that are being tested. Take a moment to review. 
Select the Next arrow to continue. 
28. Watch as the AutoAI experiment runs. This will only take 45 seconds, but would take roughly 5 
minutes when performed in the live environment. 
29. Notice that each model has four pipelines (or algorithms) for a total of eight pipelines. The pipeline 
that’s producing the most accurate predictions and is the fastest is shown with a star.  
Select the pipeline with the star. 
30. This displays the Pipeline details. By default, the ROC curve is shown. Select Confusion matrix 
from the Model viewer on the left. 
31. This displays the Confusion matrix. You will learn more about the confusion matrix and what it 
means next.

Conclusion: You successfully ran an AutoAI experiment in IBM Watson Studio. You determined which of 
the eight pipelines makes the most accurate predictions based on the data set and generated a 
confusion matrix.  
Conclusion: You successfully provisioned the IBM Watson Studio service, set up a new project, and 
uploaded the data set to your project so you’re ready to begin working with it. 


## Save AI models as Jupyter Notebooks 
1. Once you have completed your experiment and determined the best model, your next step is to save 
the model. Select Save as. 
Models and notebooks 
You’ll recall that the experiment ended by showing a confusion matrix. It’s a mathematical 
test that compares predictions from all of the algorithms to see which one worked best. 
Basically, your job is done now. The IT folks who had gathered around begin to disperse—
 except for a couple of people who linger so they can see how you’ll save and store the 
winning model. 
Select X to close this window and continue. ⓘ 
2. You have two options. You can save the model or you can save as a notebook. To use the model 
again in Watson Studio you would select Model, but to interact with the model on a deeper level you 
need to save it as a notebook. Select Notebook. 
3. The name shown in the Name field in the Define details section will change to the name of the model 
and the pipeline that Watson selected with “Notebook” at the end. Select Create. 
4. Now, select the View in project link that displays in the notification box. 
5. The Pipeline notebook displays, but it is currently view only. You need to be able to edit it. Select 
Edit icon from the menu on the top right. This makes it possible to edit the notebook. 
6. The notebook in an editable form displays, but it is not trusted. This means that the JavaScript shown 
in the notebook will be disabled and not allowed to run. Since you want to be able to run the code, 
you need to trust the notebook. Select the Not Trusted link in the upper right. 
7. This displays the Trust this notebook? dialog box. Select Trust. 
8. The display refreshed and the notebook now shows as trusted and all the JavaScript in the notebook 
is enabled. Select the Next arrow to continue. 
9. Now that your notebook is trusted, it’s time to download the notebook. Select File from the top menu. 
10. Now, select Download as. This displays the formats that you can download the notebook in. 
11. Select Notebook (.ipynb) to download the notebook in Jupyter Notebook format. 
12. This will open a new tab and automatically download the notebook in Jupyter Notebook format to your 
computer. Next, you’ll look at what you can do with the downloaded notebook.

Conclusion: You successfully saved and downloaded your IBM Watson AutoAI model. You can now use 
this model with new data sets, modify the code of the model, and even use the model on other integrated 
development environments (IDEs). 

# DAY - 9

## What is prompt tuning?

**Large language models** like ChatGPT **are flexible and can perform various tasks** such as analyzing legal documents or writing poems. Previously, **fine tuning was used to improve the performance of pre-trained models by gathering and labeling examples of the target task**. However, a more energy-efficient technique called prompt tuning has emerged as a simpler alternative. **Prompt tuning allows tailoring a massive model to a narrow task without requiring a large number of labeled examples.** 

It involves **feeding task-specific cues or prompts** to the model, which can be human-generated or AI-generated. P**rompt engineering is the development of prompts that guide models to perform specialized tasks.** Soft prompts, generated by AI, have been shown to outperform human-engineered prompts and are used in prompt tuning. They act as a substitute for additional training data. **Prompt tuning and soft prompts lack interpretability but are effective in guiding the model towards desired outputs.** Prompt tuning is proving to be a game changer in multitask learning and continual learning, allowing for swift adaptation to specialized tasks and concepts.

## Can AI help climate change?

This video discusses the intersection of artificial intelligence (AI) and climate change, specifically focusing on the role of AI in developing new materials to address the issue. The goal is **to mitigate climate change by developing low carbon technologies**.

Existing technologies face **challenges related to performance, toxicity, and stability, which impact their adoption and cost.** The **complexity of exploring various materials, processes, and operating conditions in a traditional laboratory** setting makes the problem difficult to solve. AI can play a crucial role by speeding up and enhancing the scientific method. It can **aid in generating hypotheses through natural language processing, analyzing vast amounts of scientific literature, and making meaningful connections between materials and properties. AI techniques, such as generative modeling, machine learning, and quantum chemistry, can predict and assess new materials and their performance before physical experimentation.**

AI-enhanced **simulations allow for efficient testing of materials under different conditions**, leading to the discovery of promising candidates. AI can also **optimize synthesis routes and automate laboratory processes, generating data to improve models and expand the scientific knowledge graph.** The integration of AI with the scientific method is expected to accelerate material discovery and have a significant impact on addressing climate change in the coming years.


# DAY - 10

## Natural Language Processing and Computer Vision

Every day, **computers** help you by understanding things they **hear and see.** Your phone responds to your verbal questions and commands. Traffic management systems observe streets and highways to suggest ideal routes for you to travel. Computers respond to your needs and help you make good decisions! Think of artificial intelligence (AI) as prediction machines that augment human intelligence and provide insights.

### The Debater Project

If you ask an artificial intelligence system a question on a topic for which it’s been trained, it can look up an answer. The quiz show, Jeopardy!, proved that years ago. But can an AI system carry on a continuing conversation and respond to what is said with each exchange? Let’s make this question even more difficult: **Can an AI win a debate with a human expert about a complicated topic?** To answer this question, consider a famous experiment, then learn how AI works with spoken and written language.

IBM began developing **Project Debater** in 2012, hoping to build a machine that could do more than win debates with humans. In other words, IBM Project Debater would need to be able to do more than just answer questions in a human language; it would need to have the ability to listen to a series of competitive arguments posed by humans and respond to them intelligently. **IBM's ultimate goal was to build a system that could help people make evidence-based, bias-free decisions on difficult topics where the answers aren’t obvious.**

#### It takes four steps to win a debate
**Step 1. Learn and understand the topic**
Ingest several billion passages from newspapers, books, and journals. (AI researchers call this collection of learned material a corpus.) Then, structure all that content so you can relate concepts to each other and evaluate them, even when they’re stated in different ways.


**Step 2. Build a position**
Create an opening speech made of short pieces of text pasted together from the corpus. Your speech should detail your position on the debate topic. It can’t be a jumble of phrases. It must present a compelling argument, in logical order, using good grammar.


**Step 3. Organize your proof**
Learn the deeper meaning of the facts that surround your topic. Decide what evidence is strongest and arrange your proof by themes. Adjust your arrangement each time new evidence arrives. This will help you find updated or completely new information that can score points against your opponent’s position.


**Step 4. Respond to your opponent**
Listen to your opponent’s arguments and rebuttals, then deliver a convincing rebuttal that refutes your opponent and further proves your case.

Why do we care about these four steps? Because they reflect and test four things that cognitive systems do:

![image](https://github.com/user-attachments/assets/153ce583-8392-4469-9f04-7e5c203342dc)


### Is it difficult to understand human language?

Understanding human language is difficult, even for people who have grown up with it. Human language is incredibly complex, full of strange expressions that seem to contradict each other, metaphors that require cultural knowledge to understand, and grammatical structures that sometimes turn simple ideas into tongue-twisters. Machines require systems that research scientists call natural language processing, or NLP, to understand human language. IBM Project Debater was the most complex AI system IBM Research had ever built to understand human language.

## NLP sentence segmentation and tokens

Computers are best at working with structured data, in which everything is neatly grouped and labeled. Unfortunately for machines, human language is anything but structured. You’ve been using language for most of your life. Your brain accomplishes this through some of the most complicated neural circuitry on Earth. But it is very difficult to create machines that can work with human language.

### NLP, machines segment sentences and extract meaning from “tokens” of human language

Human language is **unstructured**. Although it is **loosely held together by rules of grammar**, our language expresses information in many confusing ways. Unlike structured information, which can be arranged in tables or matrices with neatly labeled rows and columns, unstructured information is **messy and difficult to understand**. To see why, consider this famous joke by Groucho Marx.

> One morning I shot an elephant in my pajamas. How he got in my pajamas, I don’t know.
> Adapted from Groucho Marx, 20th century comedian and movie star

To deal with the **“messiness” of unstructured information**, computers begin with **one sentence at a time. This is called sentence segmentation**. Computers then break the information into **small chunks of information, called tokens**, that can be individually classified. Once the tokens in text have been sorted into a structure based on what they mean, NLP can work with them.

The following activities show you how Groucho Marx’s joke can be tokenized into useful categories called **entities and relationships**. You’ll learn the meanings of these words as you continue.

An **entity** is a noun representing a person, place, or thing. It’s not an adjective, verb, or other article of speech. I, elephant, and pajamas are entities because they are nouns. Shot, an, in, and my are not entities because they are not nouns.

A **relationship** is a group of two or more entities that have a strong connection to one another.
For I + elephant, I + pajamas, and elephant + pajamas, both words in the pair are nouns and are related entities.
I + shot is not a relationship between entities. I is a noun but shot is a not.
in + pajamas is not a relationship between entities. Pajamas is a noun but in is not.

Once an AI has classified entities and relationships in text or speech, the AI can begin structuring the information as a step toward understanding it. Your brain, by the way, does the same thing, which might have helped you find entities and relationships in the previous activities.

For example, consider the following two sentences: “Armen broke the glass. He always breaks the glass.” Notice that there is a relationship between the two sentences: the word he is related to the word Armen. The machine uses NLP to identify this relationship.

A **concept** is something **implied in a sentence but not actually stated**. This is trickier because it involves **matching ideas rather than the specific words** present in the sentence.

## Emotion detection and sentiment analysis are not the same thing

Although emotions and sentiment deal with feelings rather than facts or actions, distinguishing between them can help an AI better understand a sentence.

**Emotion detection** identifies distinct human emotion types.

For example, you can determine if the emotion being expressed is anger, happiness, or fear after reading a user's rating and comments in an online customer satisfaction survey.

AI can be trained to classify emotions. Identifying the right emotional token can make a big difference when an AI system is reading a social media post or a customer service chat, in which different emotions significantly change the meaning of a sentence.

**Sentiment analysis** isn’t a specific emotion —at least, not as computer scientists use the term. Instead, it’s a measure of the strength of an emotion. 

You can think of sentiment as a sliding scale between positive and negative, with neutral in the middle. 

Sentiment analysis is a means of assessing if data is positive, negative, or neutral.

## Human language makes classification challenging

Here’s an old-fashioned riddle:

> Why does your nose run and your feet smell?

Human language is full of terms that are **vague or have double meanings**. This is called a classification problem. In the riddle, run and smell each have two meanings.

- "A runny nose" means you have a cold and you need a tissue to wipe your nose. 
- "A smelly foot" means that your  foot has an unpleasant odor.  
It might only take you a moment to understand the joke, but an AI system might have difficulty classifying its elements. Consider these examples:

- You can ship a box by train.
- When a building burns down, it burns up.
- You can fill in a form by filling it out.
- A wise guy is not the same as a wise person.

**Classification can be more difficult for an AI system than identifying tokens** because so much of classification depends on the **context** in which a sentence is contained. Compare I went to the docks to ship my box to I went to the station to ship my box. Both sentences indicate where a box’s travel begins, but neither specifies how it will travel. An AI system must associate the word ship with either the word station or docks, and then relate that association with the right concept: either train or boat.

How does an AI system deal with this problem? After **ingesting several thousand instances** in which shipping from a dock results in boat travel, while shipping from a station leads to shipping by rail, the AI system **identifies the frequency in which places and kinds of travel are linked**. Gradually, the system gets better at classification and makes fewer mistakes. However, as with humans, an AI system’s classification will never be 100% perfect. (That’s why well-designed AI systems give not only a response, but also a confidence value.)

## Chatbot structure
If you’ve clicked a Chat button online and encountered a non-human chatbot, you might have noticed two things:

- When you ask a clear question that relates to the website’s purpose, like asking a shopping chatbot “How can I get a refund?” it usually gives you a response related to your question.
- When you ask a question that’s unclear or unrelated to the website’s purpose, like asking the shopping chatbot “Got any tickets for sister?” the response will be more along the lines of “I’m sorry, I didn’t understand your question.”
This happens because the chatbot is programmed to answer only limited questions about a particular subject.

Even with this limitation, chatbots are useful in fields ranging from retail sales to immediate care medicine. You can engage with a chatbot online at any time. A chatbot is always ready for your question (even if it cannot answer you). Some institutions use chatbots often because they don’t just broadcast ads like TV commercials. **When people engage with them, chatbots listen, and they answer repetitive questions that a business would otherwise need to pay humans to handle**.

Chatbots work with small data. This means their scale is much more limited. A movie chain’s chatbot might need to answer questions only about movie titles, locations, and times, while a more general AI that searches social media might need to answer broad questions about what millions of people think. AI researchers say that chatbots “snack on small data”.

### A chatbot has a “frontend” and a “backend”

The frontend of a chatbot is the messaging channel. The frontend interacts with the person who’s asking questions, both listening (or reading) and speaking (or presenting text).

The backend of a chatbot is where the hard work takes place. The backend operates application logic and has enough memory to remember earlier parts of a conversation as dialog continues.

## A chatbot’s backend does the hard work of understanding and responding

Suppose part of a chatbot’s job is to help you when you've lost or forgotten your password. You might enter, “How do I reset my password,” which would be easy for the chatbot to handle. To describe that action, a chatbot programmer might think in terms, such as:

> IF question = “How do I reset my password”
> THEN reply = “Here’s how to create a new password”

But humans are not always easy to understand. They might ask or type:

- “How come I can’t log into my account?!”
- “I forgot my @#$ password!”
- “It says my password is wrong.”
- “fergot paswrd”

This tells you that one chatbot response (“This is how to create a new password”) can be triggered by a large number of user queries (including all those listed, and more).

This is a great job for algorithms called **classifiers**. Classifiers can **map many different ways of asking a question to a very small set of answers**. How small? Some retail chatbots respond to hundreds of different questions with only five or six possible answers. Questions the chatbots can’t answer are sent to human customer service representatives.

## A chatbot backend usually includes three parts: intents, entities, and dialog

Chatbots understand a question by breaking it into parts and relating those parts to things in its memory. A chatbot’s goal is to identify what are called entities and intents, then use what it’s found to trigger a dialog. What do these terms mean?

### Intent

An intent is a purpose: **the reason why a user is contacting the chatbot**. Think of it as something like a verb: a kind of action. A user might intend to file a complaint, to ask for directions, to speak to a salesperson.

An institution might have many customer or member intents that it would like a chatbot to handle. Suppose you’ve been hired to help create a chatbot for a restaurant chain. One possible intent would be to find out when the restaurants are open. You might first interview a person who previously handled many forms of this question on the phone. Then, your task would be to list all the different ways a caller might ask about when the restaurants are open. The following table provides many examples of possible user inputs that map to this kind of intent.

![image](https://github.com/user-attachments/assets/6bdfe2e0-994a-43af-bd41-24acde3e64e0)

If a user asks, “What are the hours for the Austin location?”, then providing **business hours is the intent and Austin is the entity**. A chatbot needs a full list of entities in order to be helpful.

### Dialog

A dialog is a **flowchart—an IF / THEN tree structure that illustrates how a machine will respond to user intents.** A dialog is what the machine replies after a human asks a question. Even if a human uses run-on sentences, poor grammar, chat messaging expressions, and so on, artificial intelligence allows the NLP to understand well enough to provide a response.

The dialog represents each possible word or phrase a user might enter, the matched response for the chatbot, and the many possible subsequent replies a user might make next. That’s too much for an ordinary flowchart to show (you might need three or four dimensions!), so chatbot software **condenses each moment of the conversation into a node**. A node contains a statement by the chatbot and a long, expandable list of possible replies.

Planning this flowchart would be an adventure! You’d need to assign a reply to every possible user input after the chatbot’s greeting. For the restaurant hours example, all possible questions about a restaurant’s hours would lead to a single reply. This would continue for the next question (perhaps for the restaurant’s address), and so on. A large number of possible questions would be mapped onto a small number of possible answers until the conversation is ended. (Spoiler: It helps that today’s virtual assistants already have been trained on Wikipedia, so they know, for example, the difference between a wise man and a wise guy.)

## Intents, entities, and dialogs make quick work for NLP

In a conventional computer, the program code is stupendously large but wouldn’t handle intents, entities, and dialogs very well. A conventional computer would need a separate IF / THEN line for many thousands of ways a question might be asked. Unless a human were to match one of those lines perfectly, the computer would fail. 

But an AI system’s combination of NLP with intents, entities, and dialog can make quick work of this. NLP analyzes sentence components, then uses processes like passage and evidence scoring to classify the sentence components against possible chatbot responses. The result is that when a human user asks a question, the AI system provides the answer with the highest confidence.

Consider Staples, the office supply company that features the Easy button. Suppose a customer asks for a chatbot on Staples’ website. The chatbot’s frontend receives the customer’s inquiry, then forwards it to the chatbot’s backend. There, IBM Watson Assistant runs the NLP to understand the human’s intentions regarding ordering a product or tracking a shipment.

If the customer says, “I want to reorder black pens,” the chatbot figures out what that means. Then, it uses cognitive services to pull up the customer’s purchase history. Within seconds, the system is helping the customer buy more pens.

The Staples chatbot only knows five things, but it knows them well. It supports online sales 24 hours a day, giving callers round-the-clock service while leaving human staff free to do other work. This is valuable for both the customers and the business.


# DAY - 11

## Convolutional neural networks

> An AI system uses a convolutional neural network (CNN) to analyze images

Digital photos and videos build **images with millions of pixels**—tiny dots that, taken together, give the human eye the illusion of a two-dimensional image. Each pixel has one of several million brightness and color levels that can be expressed in numbers. A computer (including the camera in a cellphone) can look at each of those pixels and input or output its numbers, either recording (input) or displaying (output) an image. But it’s one thing to display an image and another, much more complicated thing to analyze it.

The **problem is caused by those millions of pixels** with their color and brightness levels. They **add up to numbers so large that they would overwhelm most AI systems**. (Research scientists say that too much data can “flood” a system.) To get around this, research scientists have devised **a clever way to analyze only small parts of an image at a time**. This process, called a **convolutional neural network, or CNN**, makes it possible for visual recognition systems to identify things in an image, as in facial recognition.

Here’s a clear and concise **note summary** from the video transcript you shared about **Convolutional Neural Networks (CNNs):**

---

### **Convolutional Neural Networks (CNNs)**

#### **Introduction**

* CNN = *Convolutional Neural Network*
* A **deep learning** technique specialized in **pattern recognition**.
* Inspired by how humans recognize objects easily, even in abstract or simplified forms (e.g., drawing of a house).
* Used to help computers perform **object identification** tasks.

---

#### **Key Components of CNN**

1. **Artificial Neural Network (ANN) Basics**

   * Consists of **multiple layers**:

     * Each layer takes input → transforms it → passes output to next layer.

2. **Convolution Layers & Filters**

   * **Filters**: Small matrices (e.g., 3×3 blocks) applied over the image.
   * They **slide over (convolve)** the image to detect patterns.

     * Example: Look for right angles, lines, or edges in an image.
   * Each filter produces a **numeric array** showing how closely parts of the image match the pattern.

3. **Pooling**

   * Combines results from multiple filters.
   * Helps reduce dimensionality while preserving important information.

---

#### 🏠 **Example: Identifying a House**

* Image = collection of pixels.
* CNN uses filters to detect:

  * **First layers**: Basic patterns (e.g., straight lines, edges).
  * **Deeper layers**: More abstract features (e.g., windows, doors, roofs).
  * **Final layers**: Complete objects (e.g., house vs apartment vs skyscraper).

---

#### 🚀 **Applications of CNN**

* **Optical Character Recognition (OCR)** – Reading handwritten text.
* **Visual recognition** – Object detection & classification.
* **Facial detection** – Identifying faces in images/videos.
* **Medical imagery** – Analyzing scans for diagnosis.
* **Visual search** – Finding images similar to a query image.

## Generative adversarial networks

> A visual recognition system can use a generative adversarial network (GAN) to create new drawings and photos

Recall that an AI system can analyze a photo using a neural network to identify a photo. But what about AI systems themselves that create imaginary photos?

You might have heard of computer-generated **“deep fakes”**: computer-generated images that look like they were taken from real life. You might have also seen drawings or handwriting created by AI “artists”. How does a system do this? One way is by **pitting two convolutional neural networks (CNNs) against each other in a “contest” called a generative adversarial network, or GAN**. In effect, the CNNs battle each other until one of them becomes pretty good at creating art.


### **Generative Adversarial Networks (GANs)**

#### **Introduction**

* GAN stands for Generative Adversarial Network.
* It involves two AI models competing against each other, hence the term *“adversarial.”*
* GANs are a type of unsupervised learning where the system supervises itself.

---

#### **Key Components**

1. **Two Sub-Models**

   * **Generator**: Creates fake samples (e.g., fake images of flowers).
   * **Discriminator**: Decides whether a sample is real (from actual data) or fake (created by the generator).

2. **Adversarial Process**

   * The generator tries to fool the discriminator with realistic fake data.
   * The discriminator tries to correctly identify real versus fake data.
   * The winner (correct model) remains unchanged, while the loser updates its model.
   * This process repeats many times until the generator’s fake data is so convincing that the discriminator can no longer distinguish it from real data.

---

#### **Example: Training GAN with Flower Images**

1. The discriminator is first trained on real flower images to learn their attributes such as color, shading, and shape.
2. Once the discriminator becomes effective at distinguishing real flowers, the generator starts creating fake flower images.
3. The discriminator evaluates whether each image is real or fake.
4. Based on the result:

   * If the discriminator correctly detects the fake, the generator updates to create better fakes.
   * If the generator successfully fools the discriminator, the discriminator updates to improve its detection ability.
5. This adversarial loop continues until the generator produces highly convincing images.

---

#### **Key Characteristics**

* Zero-sum game: In each iteration, either the generator or the discriminator improves.
* Both models progressively enhance each other’s performance.

---

#### **Applications of GANs**

* **Image Generation**: Creating fake faces, objects, animals.
* **Video Frame Prediction**: Predicting the next frame in a video sequence, useful in surveillance.
* **Image Enhancement**: Upscaling low-resolution images to higher resolution.
* **Encryption**: Developing secure encryption algorithms using the iterative GAN process.

---

#### **Implementation Note**

* Both the generator and discriminator are often implemented using Convolutional Neural Networks (CNNs) because CNNs are effective at identifying patterns in image data.

---

#### **Key Takeaways**

* GANs involve a generator and discriminator working against each other to improve over time.
* They produce highly realistic data and have applications beyond images, including video and encryption.
* Many iterations are needed for the generator to achieve mastery in creating convincing outputs.

## Computer vision has many useful applications

- The IBM Maximo visual inspection system can be equipped with video cameras on drones. It can not only detect problems, like cracks in a suspension bridge, but identify which problems (cracks, in this example) are dangerous and should be repaired.
- Spotting a dangerous but difficult-to-detect flaw in an airplane’s wing
- Monitoring water flow across a dairy farm to ensure it doesn’t reach nearby food crops
- Counting the number of people in an unruly crowd
- Classifying animal and plant populations to measure biodiversity in a forest
- Performing lip-reading for people who cannot hear or speak
